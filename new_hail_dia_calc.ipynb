{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e878ca5-67f5-40f6-824b-6e0e30e1fd65",
   "metadata": {},
   "source": [
    "## Hail Calculation with simple approach\n",
    "\n",
    "### ðŸ’§ Massâ€“Diameter Relationship for Hydrometeors\n",
    "\n",
    "This method is based on a simple **massâ€“diameter relationship** using:\n",
    "\n",
    "$$\n",
    "m = \\frac{q}{n}\n",
    "$$\n",
    "\n",
    "> where:\n",
    "> $m$ = average mass per particle \\[kg]\n",
    "> $q$ = mass mixing ratio \\[kg/kg]\n",
    "> $n$ = number concentration \\[#/kg]\n",
    "\n",
    "---\n",
    "\n",
    "Assuming **spherical particles**, the volumeâ€“mass relation is:\n",
    "\n",
    "$$\n",
    "m = \\frac{\\pi}{6} \\rho_p D^3 \\quad \\Rightarrow \\quad D = \\left( \\frac{6m}{\\pi \\rho_p} \\right)^{1/3}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $\\rho_p$ = particle material density \\[kg/mÂ³]\n",
    "* $D$ = diameter \\[m]\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Œ Suggested Hydrometeor Densities\n",
    "\n",
    "Use realistic values for $\\rho_p$ depending on the particle type:\n",
    "\n",
    "* **Rain**: \\~1000 kg/mÂ³\n",
    "* **Graupel**: \\~400â€“500 kg/mÂ³\n",
    "* **Hail**: \\~700â€“900 kg/mÂ³\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Final Formula (Diameter in meters)\n",
    "\n",
    "$$\n",
    "D = \\left( \\frac{6 \\cdot \\frac{q}{n}}{\\pi \\cdot \\rho_p} \\right)^{1/3}\n",
    "$$\n",
    "\n",
    "Or simplified:\n",
    "\n",
    "$$\n",
    "D = \\left( \\frac{6q}{n \\pi \\rho_p} \\right)^{1/3}\n",
    "$$\n",
    "\n",
    "Where you define $\\rho_p$ as appropriate for each hydrometeor type.\n",
    "\n",
    "---\n",
    "\n",
    "Let me know if you also want a version rendered for PDF or presentation slides.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e95a5eab-3ccc-4046-a4c6-9f75dde46f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Function to calculate diameter ===\n",
    "def compute_d(q, n, rho_p):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        m = xr.where(n > 0, q / n, np.nan)\n",
    "        D = ((6 * m) / (np.pi * rho_p))**(1/3)\n",
    "    return D\n",
    "\n",
    "def calculate_hydrometeor_diameters(ds):\n",
    "    # Prescribed hydrometeor densities [kg/mÂ³]\n",
    "    rho_rain = 1000.0\n",
    "    rho_graupel = 500.0\n",
    "    rho_hail = 900.0\n",
    "\n",
    "    qr = ds[\"qr\"]\n",
    "    nr = ds[\"nr\"]\n",
    "    qg = ds[\"qg\"]\n",
    "    ng = ds[\"ng\"]\n",
    "    qh = ds[\"qh\"]\n",
    "    nh = ds[\"nh\"]\n",
    "\n",
    "    time_dim = ds.sizes[\"time\"]\n",
    "    diam_rain = []\n",
    "    diam_graupel = []\n",
    "    diam_hail = []\n",
    "\n",
    "    for t in tqdm(range(time_dim), desc=\"Calculating diameters over time\"):\n",
    "        d_rain = compute_d(qr.isel(time=t), nr.isel(time=t), rho_rain)\n",
    "        d_grau = compute_d(qg.isel(time=t), ng.isel(time=t), rho_graupel)\n",
    "        d_hail = compute_d(qh.isel(time=t), nh.isel(time=t), rho_hail)\n",
    "\n",
    "        diam_rain.append(d_rain)\n",
    "        diam_graupel.append(d_grau)\n",
    "        diam_hail.append(d_hail)\n",
    "\n",
    "    # Stack back into DataArray with time\n",
    "    rain_d_da = xr.concat(diam_rain, dim=\"time\")\n",
    "    graupel_d_da = xr.concat(diam_graupel, dim=\"time\")\n",
    "    hail_d_da = xr.concat(diam_hail, dim=\"time\")\n",
    "\n",
    "    rain_d_da.name = \"diameter_raindrop\"\n",
    "    graupel_d_da.name = \"diameter_graupel\"\n",
    "    hail_d_da.name = \"diameter_hail\"\n",
    "\n",
    "    rain_d_da.attrs = {'units': 'm', 'long_name': 'Raindrop diameter'}\n",
    "    graupel_d_da.attrs = {'units': 'm', 'long_name': 'Graupel diameter'}\n",
    "    hail_d_da.attrs = {'units': 'm', 'long_name': 'Hail diameter'}\n",
    "\n",
    "    return rain_d_da, graupel_d_da, hail_d_da\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27467738-02cb-4f84-8962-68393b5742e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing set 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating diameters over time: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 121/121 [11:50<00:00,  5.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data/filtered_w10_new_dia_set2.nc\n",
      "\n",
      "Processing set 12...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating diameters over time: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 121/121 [12:18<00:00,  6.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data/filtered_w10_new_dia_set12.nc\n",
      "\n",
      "Processing set 11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating diameters over time: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 121/121 [12:13<00:00,  6.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data/filtered_w10_new_dia_set11.nc\n",
      "\n",
      "Processing set 8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating diameters over time: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 121/121 [12:11<00:00,  6.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data/filtered_w10_new_dia_set8.nc\n",
      "\n",
      "Processing set 9...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating diameters over time: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 121/121 [12:13<00:00,  6.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data/filtered_w10_new_dia_set9.nc\n",
      "\n",
      "Processing set 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating diameters over time: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 121/121 [12:04<00:00,  5.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data/filtered_w10_new_dia_set10.nc\n",
      "\n",
      "Processing set 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating diameters over time: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 121/121 [12:16<00:00,  6.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data/filtered_w10_new_dia_set5.nc\n"
     ]
    }
   ],
   "source": [
    "# === Input/Output Setup ===\n",
    "input_dir = \"/glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data\"\n",
    "output_dir = \"/glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data\"\n",
    "\n",
    "selected_sets = [2, 12, 11, 8, 9, 10, 5]\n",
    "file_template = \"filtered_w10_new_set{}.nc\"\n",
    "\n",
    "for i in selected_sets:\n",
    "    path_in = os.path.join(input_dir, file_template.format(i))\n",
    "    path_out = os.path.join(output_dir, f\"filtered_w10_new_dia_set{i}.nc\")\n",
    "\n",
    "    if os.path.exists(path_in):\n",
    "        print(f\"\\nProcessing set {i}...\")\n",
    "        ds = xr.open_dataset(path_in)\n",
    "\n",
    "        rain_d, graupel_d, hail_d = calculate_hydrometeor_diameters(ds)\n",
    "\n",
    "        # Merge and save\n",
    "        ds_out = ds.copy()\n",
    "        ds_out[\"diameter_raindrop\"] = rain_d\n",
    "        ds_out[\"diameter_graupel\"] = graupel_d\n",
    "        ds_out[\"diameter_hail\"] = hail_d\n",
    "\n",
    "        ds_out.to_netcdf(path_out)\n",
    "        print(f\"Saved: {path_out}\")\n",
    "    else:\n",
    "        print(f\"File not found: {path_in}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfe77d6-1298-4743-a16a-127b1ccc90cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# === Input Directory and File Pattern ===\n",
    "input_dir = \"/glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data\"\n",
    "selected_sets = [2, 12, 11, 8, 9, 10, 5]\n",
    "file_template = \"filtered_w10_new_dia_set{}.nc\"\n",
    "\n",
    "# === Variable Conversion Mapping (name, units, scale factor) ===\n",
    "variables = {\n",
    "    \"diameter_raindrop\": {\"label\": \"Raindrop\", \"unit\": \"Âµm\", \"scale\": 1e6},\n",
    "    \"diameter_graupel\": {\"label\": \"Graupel\", \"unit\": \"mm\", \"scale\": 1e3},\n",
    "    \"diameter_hail\": {\"label\": \"Hail\", \"unit\": \"mm\", \"scale\": 1e3},\n",
    "}\n",
    "\n",
    "# === Store results grouped by variable\n",
    "stats_by_var = {var: {} for var in variables}\n",
    "\n",
    "# === Loop over datasets\n",
    "for i in selected_sets:\n",
    "    file_path = os.path.join(input_dir, file_template.format(i))\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    ds = xr.open_dataset(file_path)\n",
    "\n",
    "    for varname, props in variables.items():\n",
    "        if varname not in ds:\n",
    "            print(f\"Variable {varname} not found in set {i}\")\n",
    "            continue\n",
    "\n",
    "        data = ds[varname] * props[\"scale\"]\n",
    "        vals = data.values.flatten()\n",
    "        vals = vals[~np.isnan(vals)]\n",
    "\n",
    "        # Compute statistics\n",
    "        stats = {\n",
    "            \"max\": np.nanmax(vals),\n",
    "            \"p99\": np.nanpercentile(vals, 99),\n",
    "            \"p95\": np.nanpercentile(vals, 95),\n",
    "            \"median\": np.nanmedian(vals),\n",
    "            \"mean\": np.nanmean(vals),\n",
    "        }\n",
    "\n",
    "        stats_by_var[varname][f\"set{i}\"] = stats\n",
    "\n",
    "    ds.close()\n",
    "\n",
    "# === Print grouped by variable\n",
    "for varname, set_stats in stats_by_var.items():\n",
    "    label = variables[varname][\"label\"]\n",
    "    unit = variables[varname][\"unit\"]\n",
    "    print(f\"\\n=== {label} Diameter Stats [{unit}] ===\")\n",
    "    print(f\"{'Dataset':<8}  {'Max':>8}  {'99th':>8}  {'95th':>8}  {'Median':>8}  {'Mean':>8}\")\n",
    "    print(\"-\" * 55)\n",
    "    for dataset, stats in set_stats.items():\n",
    "        print(f\"{dataset:<8}  {stats['max']:8.2f}  {stats['p99']:8.2f}  {stats['p95']:8.2f}  \"\n",
    "              f\"{stats['median']:8.2f}  {stats['mean']:8.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbdc470-6d6c-452b-94b4-6eee0903fac2",
   "metadata": {},
   "source": [
    "#### Raindrop Size Diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0efd33fa-5f59-4856-b14e-e48c77124a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Function to calculate diameter ===\n",
    "def compute_dr(q, n, rho_p):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        m = xr.where(n > 0, q / n, np.nan)\n",
    "        D = ((6 * m) / (np.pi * rho_p))**(1/3)\n",
    "    return D\n",
    "\n",
    "def calculate_hydrometeor_diameter_rain(ds):\n",
    "    # Prescribed hydrometeor densities [kg/mÂ³]\n",
    "    rho_rain = 1000.0\n",
    "\n",
    "    qr = ds[\"qr\"]\n",
    "    nr = ds[\"nr\"]\n",
    "\n",
    "    time_dim = ds.sizes[\"time\"]\n",
    "    diam_rain = []\n",
    "\n",
    "    for t in tqdm(range(time_dim), desc=\"Calculating diameters over time\"):\n",
    "        d_rain = compute_dr(qr.isel(time=t), nr.isel(time=t), rho_rain)\n",
    "\n",
    "        diam_rain.append(d_rain)\n",
    "\n",
    "    # Stack back into DataArray with time\n",
    "    rain_d_da = xr.concat(diam_rain, dim=\"time\")\n",
    "    rain_d_da.name = \"diameter_raindrop\"\n",
    "    rain_d_da.attrs = {'units': 'm', 'long_name': 'Raindrop diameter'}\n",
    "    \n",
    "    return rain_d_da\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad6dc5d7-0e73-41a5-8d94-d6ce67de80b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing set 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating diameters over time: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [03:33<00:00,  2.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data/filtered_w5_hres_new_dia_set1.nc\n",
      "\n",
      "Processing set 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating diameters over time: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [03:31<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data/filtered_w5_hres_new_dia_set2.nc\n",
      "\n",
      "Processing set 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating diameters over time: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [03:23<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data/filtered_w5_hres_new_dia_set3.nc\n",
      "\n",
      "Processing set 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating diameters over time: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [03:20<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data/filtered_w5_hres_new_dia_set4.nc\n",
      "\n",
      "Processing set 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating diameters over time: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [03:22<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data/filtered_w5_hres_new_dia_set5.nc\n",
      "\n",
      "Processing set 6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating diameters over time: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [03:21<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data/filtered_w5_hres_new_dia_set6.nc\n",
      "\n",
      "Processing set 7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating diameters over time: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [03:22<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data/filtered_w5_hres_new_dia_set7.nc\n"
     ]
    }
   ],
   "source": [
    "# === Input/Output Setup ===\n",
    "input_dir = \"/glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data\"\n",
    "output_dir = \"/glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data\"\n",
    "\n",
    "selected_sets = [1, 2, 3, 4, 5, 6, 7]\n",
    "file_template = \"filtered_w5_hres_set{}.nc\"\n",
    "\n",
    "for i in selected_sets:\n",
    "    path_in = os.path.join(input_dir, file_template.format(i))\n",
    "    path_out = os.path.join(output_dir, f\"filtered_w5_hres_new_dia_set{i}.nc\")\n",
    "\n",
    "    if os.path.exists(path_in):\n",
    "        print(f\"\\nProcessing set {i}...\")\n",
    "        ds = xr.open_dataset(path_in)\n",
    "\n",
    "        rain_d = calculate_hydrometeor_diameter_rain(ds)\n",
    "\n",
    "        # Merge and save\n",
    "        ds_out = ds.copy()\n",
    "        ds_out[\"diameter_raindrop\"] = rain_d\n",
    "        \n",
    "        ds_out.to_netcdf(path_out)\n",
    "        print(f\"Saved: {path_out}\")\n",
    "    else:\n",
    "        print(f\"File not found: {path_in}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d163fee-1da9-48ee-b068-29aad7e75498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Raindrop Diameter Stats [Âµm] ===\n",
      "Dataset        Max      99th      95th    Median      Mean\n",
      "-------------------------------------------------------\n",
      "set1        775.70    328.96    175.87     98.18    105.76\n",
      "set2        745.38    271.13    126.46     94.54    100.35\n",
      "set3        787.39    263.13    138.42     95.76    100.96\n",
      "set4        630.69    222.27    123.16     94.44     98.80\n",
      "set5        409.40    201.87    118.53     93.39     97.41\n",
      "set6        516.55    203.27    115.17     92.03     96.62\n",
      "set7        625.46    250.93    128.36     92.41     98.72\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# === Input Directory and File Pattern ===\n",
    "input_dir = \"/glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data\"\n",
    "selected_sets = [1, 2, 3, 4, 5, 6, 7]\n",
    "file_template = \"filtered_w5_hres_new_dia_set{}.nc\"\n",
    "\n",
    "# === Variable Conversion Mapping (name, units, scale factor) ===\n",
    "variables = {\n",
    "    \"diameter_raindrop\": {\"label\": \"Raindrop\", \"unit\": \"Âµm\", \"scale\": 1e6},\n",
    "}\n",
    "\n",
    "# === Store results grouped by variable\n",
    "stats_by_var = {var: {} for var in variables}\n",
    "\n",
    "# === Loop over datasets\n",
    "for i in selected_sets:\n",
    "    file_path = os.path.join(input_dir, file_template.format(i))\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    ds = xr.open_dataset(file_path)\n",
    "\n",
    "    for varname, props in variables.items():\n",
    "        if varname not in ds:\n",
    "            print(f\"Variable {varname} not found in set {i}\")\n",
    "            continue\n",
    "\n",
    "        data = ds[varname] * props[\"scale\"]\n",
    "        vals = data.values.flatten()\n",
    "        vals = vals[~np.isnan(vals)]\n",
    "\n",
    "        # Compute statistics\n",
    "        stats = {\n",
    "            \"max\": np.nanmax(vals),\n",
    "            \"p99\": np.nanpercentile(vals, 99),\n",
    "            \"p95\": np.nanpercentile(vals, 95),\n",
    "            \"median\": np.nanmedian(vals),\n",
    "            \"mean\": np.nanmean(vals),\n",
    "        }\n",
    "\n",
    "        stats_by_var[varname][f\"set{i}\"] = stats\n",
    "\n",
    "    ds.close()\n",
    "\n",
    "# === Print grouped by variable\n",
    "for varname, set_stats in stats_by_var.items():\n",
    "    label = variables[varname][\"label\"]\n",
    "    unit = variables[varname][\"unit\"]\n",
    "    print(f\"\\n=== {label} Diameter Stats [{unit}] ===\")\n",
    "    print(f\"{'Dataset':<8}  {'Max':>8}  {'99th':>8}  {'95th':>8}  {'Median':>8}  {'Mean':>8}\")\n",
    "    print(\"-\" * 55)\n",
    "    for dataset, stats in set_stats.items():\n",
    "        print(f\"{dataset:<8}  {stats['max']:8.2f}  {stats['p99']:8.2f}  {stats['p95']:8.2f}  \"\n",
    "              f\"{stats['median']:8.2f}  {stats['mean']:8.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43bfc441-2a71-4cf2-85c2-4579861189f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing set 6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating diameters over time: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [03:31<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data/filtered_w3_hres_new_dia_set6.nc\n",
      "\n",
      "Processing set 7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating diameters over time: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [04:01<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data/filtered_w3_hres_new_dia_set7.nc\n"
     ]
    }
   ],
   "source": [
    "# === Input/Output Setup ===\n",
    "input_dir = \"/glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data\"\n",
    "output_dir = \"/glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data\"\n",
    "\n",
    "selected_sets = [6, 7]\n",
    "file_template = \"filtered_w3_hres_set{}.nc\"\n",
    "\n",
    "for i in selected_sets:\n",
    "    path_in = os.path.join(input_dir, file_template.format(i))\n",
    "    path_out = os.path.join(output_dir, f\"filtered_w3_hres_new_dia_set{i}.nc\")\n",
    "\n",
    "    if os.path.exists(path_in):\n",
    "        print(f\"\\nProcessing set {i}...\")\n",
    "        ds = xr.open_dataset(path_in)\n",
    "\n",
    "        rain_d = calculate_hydrometeor_diameter_rain(ds)\n",
    "\n",
    "        # Merge and save\n",
    "        ds_out = ds.copy()\n",
    "        ds_out[\"diameter_raindrop\"] = rain_d\n",
    "        \n",
    "        ds_out.to_netcdf(path_out)\n",
    "        print(f\"Saved: {path_out}\")\n",
    "    else:\n",
    "        print(f\"File not found: {path_in}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9112d829-f95f-4bdd-a47e-27560f23963c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Raindrop Diameter Stats [Âµm] ===\n",
      "Dataset        Max      99th      95th    Median      Mean\n",
      "-------------------------------------------------------\n",
      "set1        775.70    313.00    166.91     97.13    104.34\n",
      "set2        745.38    256.02    126.78     94.87     99.87\n",
      "set3        787.39    256.93    138.04     95.61    100.61\n",
      "set4        630.69    223.13    125.37     94.68     98.77\n",
      "set5        418.57    214.42    123.24     93.91     97.99\n",
      "set6        516.55    221.57    120.96     92.87     97.54\n",
      "set7        625.46    231.46    117.42     91.78     96.91\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# === Input Directory and File Pattern ===\n",
    "input_dir = \"/glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data\"\n",
    "selected_sets = [1, 2, 3, 4, 5, 6, 7]\n",
    "file_template = \"filtered_w3_hres_new_dia_set{}.nc\"\n",
    "\n",
    "# === Variable Conversion Mapping (name, units, scale factor) ===\n",
    "variables = {\n",
    "    \"diameter_raindrop\": {\"label\": \"Raindrop\", \"unit\": \"Âµm\", \"scale\": 1e6},\n",
    "}\n",
    "\n",
    "# === Store results grouped by variable\n",
    "stats_by_var = {var: {} for var in variables}\n",
    "\n",
    "# === Loop over datasets\n",
    "for i in selected_sets:\n",
    "    file_path = os.path.join(input_dir, file_template.format(i))\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    ds = xr.open_dataset(file_path)\n",
    "\n",
    "    for varname, props in variables.items():\n",
    "        if varname not in ds:\n",
    "            print(f\"Variable {varname} not found in set {i}\")\n",
    "            continue\n",
    "\n",
    "        data = ds[varname] * props[\"scale\"]\n",
    "        vals = data.values.flatten()\n",
    "        vals = vals[~np.isnan(vals)]\n",
    "\n",
    "        # Compute statistics\n",
    "        stats = {\n",
    "            \"max\": np.nanmax(vals),\n",
    "            \"p99\": np.nanpercentile(vals, 99),\n",
    "            \"p95\": np.nanpercentile(vals, 95),\n",
    "            \"median\": np.nanmedian(vals),\n",
    "            \"mean\": np.nanmean(vals),\n",
    "        }\n",
    "\n",
    "        stats_by_var[varname][f\"set{i}\"] = stats\n",
    "\n",
    "    ds.close()\n",
    "\n",
    "# === Print grouped by variable\n",
    "for varname, set_stats in stats_by_var.items():\n",
    "    label = variables[varname][\"label\"]\n",
    "    unit = variables[varname][\"unit\"]\n",
    "    print(f\"\\n=== {label} Diameter Stats [{unit}] ===\")\n",
    "    print(f\"{'Dataset':<8}  {'Max':>8}  {'99th':>8}  {'95th':>8}  {'Median':>8}  {'Mean':>8}\")\n",
    "    print(\"-\" * 55)\n",
    "    for dataset, stats in set_stats.items():\n",
    "        print(f\"{dataset:<8}  {stats['max']:8.2f}  {stats['p99']:8.2f}  {stats['p95']:8.2f}  \"\n",
    "              f\"{stats['median']:8.2f}  {stats['mean']:8.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58377be5-67d5-4475-af57-173b28b8676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Function to calculate diameter ===\n",
    "def compute_d(q, n, rho_p):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        m = xr.where(n > 0, q / n, np.nan)\n",
    "        D = ((6 * m) / (np.pi * rho_p))**(1/3)\n",
    "    return D\n",
    "\n",
    "def calculate_hydrometeor_diameter_hg(ds):\n",
    "    # Prescribed hydrometeor densities [kg/mÂ³]\n",
    "    rho_graupel = 500.0\n",
    "    rho_hail = 900.0\n",
    "    \n",
    "    qg = ds[\"qg\"]\n",
    "    ng = ds[\"ng\"]\n",
    "    qh = ds[\"qh\"]\n",
    "    nh = ds[\"nh\"]\n",
    "\n",
    "    time_dim = ds.sizes[\"time\"]\n",
    "    diam_graupel = []\n",
    "    diam_hail = []\n",
    "\n",
    "    for t in tqdm(range(time_dim), desc=\"Calculating diameters over time\"):\n",
    "        d_grau = compute_d(qg.isel(time=t), ng.isel(time=t), rho_graupel)\n",
    "        d_hail = compute_d(qh.isel(time=t), nh.isel(time=t), rho_hail)\n",
    "\n",
    "        diam_graupel.append(d_grau)\n",
    "        diam_hail.append(d_hail)\n",
    "\n",
    "    # Stack back into DataArray with time\n",
    "    graupel_d_da = xr.concat(diam_graupel, dim=\"time\")\n",
    "    hail_d_da = xr.concat(diam_hail, dim=\"time\")\n",
    "\n",
    "    graupel_d_da.name = \"diameter_graupel\"\n",
    "    hail_d_da.name = \"diameter_hail\"\n",
    "\n",
    "    graupel_d_da.attrs = {'units': 'm', 'long_name': 'Graupel diameter'}\n",
    "    hail_d_da.attrs = {'units': 'm', 'long_name': 'Hail diameter'}\n",
    "\n",
    "    return graupel_d_da, hail_d_da\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbdfe5d8-1ef3-44f0-a18c-97cb24cbd48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing set 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating diameters over time: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [15:35<00:00,  9.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data/filtered_w5_hg_new_dia_set1.nc\n",
      "\n",
      "Processing set 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating diameters over time: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [26:43<00:00, 15.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data/filtered_w5_hg_new_dia_set2.nc\n",
      "\n",
      "Processing set 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating diameters over time: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [22:52<00:00, 13.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data/filtered_w5_hg_new_dia_set3.nc\n",
      "\n",
      "Processing set 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating diameters over time: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [22:59<00:00, 13.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data/filtered_w5_hg_new_dia_set4.nc\n",
      "\n",
      "Processing set 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating diameters over time: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [18:06<00:00, 10.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data/filtered_w5_hg_new_dia_set5.nc\n"
     ]
    }
   ],
   "source": [
    "# === Input/Output Setup ===\n",
    "input_dir = \"/glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data\"\n",
    "output_dir = \"/glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data\"\n",
    "\n",
    "selected_sets = [1, 2, 3, 4, 5]\n",
    "file_template = \"filtered_w5_hg_new_set{}.nc\"\n",
    "\n",
    "for i in selected_sets:\n",
    "    path_in = os.path.join(input_dir, file_template.format(i))\n",
    "    path_out = os.path.join(output_dir, f\"filtered_w5_hg_new_dia_set{i}.nc\")\n",
    "\n",
    "    if os.path.exists(path_in):\n",
    "        print(f\"\\nProcessing set {i}...\")\n",
    "        ds = xr.open_dataset(path_in)\n",
    "\n",
    "        graupel_d, hail_d = calculate_hydrometeor_diameter_hg(ds)\n",
    "\n",
    "        # Merge and save\n",
    "        ds_out = ds.copy()\n",
    "        ds_out[\"diameter_graupel\"] = graupel_d\n",
    "        ds_out[\"diameter_hail\"] = hail_d\n",
    "\n",
    "        ds_out.to_netcdf(path_out)\n",
    "        print(f\"Saved: {path_out}\")\n",
    "    else:\n",
    "        print(f\"File not found: {path_in}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35a5e5c8-0486-488d-8256-8a7a3465577e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing set 6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating diameters over time: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [17:49<00:00, 10.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data/filtered_w5_hg_new_dia_set6.nc\n",
      "\n",
      "Processing set 7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating diameters over time: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [17:22<00:00, 10.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data/filtered_w5_hg_new_dia_set7.nc\n"
     ]
    }
   ],
   "source": [
    "# === Input/Output Setup ===\n",
    "input_dir = \"/glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data\"\n",
    "output_dir = \"/glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data\"\n",
    "\n",
    "selected_sets = [6, 7]\n",
    "file_template = \"filtered_w5_hg_new_set{}.nc\"\n",
    "\n",
    "for i in selected_sets:\n",
    "    path_in = os.path.join(input_dir, file_template.format(i))\n",
    "    path_out = os.path.join(output_dir, f\"filtered_w5_hg_new_dia_set{i}.nc\")\n",
    "\n",
    "    if os.path.exists(path_in):\n",
    "        print(f\"\\nProcessing set {i}...\")\n",
    "        ds = xr.open_dataset(path_in)\n",
    "\n",
    "        graupel_d, hail_d = calculate_hydrometeor_diameter_hg(ds)\n",
    "\n",
    "        # Merge and save\n",
    "        ds_out = ds.copy()\n",
    "        ds_out[\"diameter_graupel\"] = graupel_d\n",
    "        ds_out[\"diameter_hail\"] = hail_d\n",
    "\n",
    "        ds_out.to_netcdf(path_out)\n",
    "        print(f\"Saved: {path_out}\")\n",
    "    else:\n",
    "        print(f\"File not found: {path_in}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f62bd055-7ce7-4719-9b12-d52d6f9d49e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation fmax which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 39\u001b[0m\n\u001b[1;32m     35\u001b[0m     vals \u001b[38;5;241m=\u001b[39m vals[\u001b[38;5;241m~\u001b[39mnp\u001b[38;5;241m.\u001b[39misnan(vals)]\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# Compute statistics\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     stats \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m---> 39\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp99\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mnanpercentile(vals, \u001b[38;5;241m99\u001b[39m),\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp95\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mnanpercentile(vals, \u001b[38;5;241m95\u001b[39m),\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mnanmedian(vals),\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mnanmean(vals),\n\u001b[1;32m     44\u001b[0m        }\n\u001b[1;32m     45\u001b[0m     stats_by_var[varname][\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m stats\n\u001b[1;32m     47\u001b[0m ds\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/glade/u/apps/opt/conda/envs/npl-2024b/lib/python3.11/site-packages/numpy/lib/nanfunctions.py:476\u001b[0m, in \u001b[0;36mnanmax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m    471\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhere\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m where\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(a) \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;129;01mand\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;66;03m# Fast, but not safe for subclasses of ndarray, or object arrays,\u001b[39;00m\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;66;03m# which do not implement isnan (gh-9009), or fmax correctly (gh-8975)\u001b[39;00m\n\u001b[0;32m--> 476\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(res)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    478\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll-NaN slice encountered\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m,\n\u001b[1;32m    479\u001b[0m                       stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation fmax which has no identity"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# === Input Directory and File Pattern ===\n",
    "input_dir = \"/glade/derecho/scratch/fsari/CM1/DATA/new_ramp/bismillah_final/filtered_data\"\n",
    "selected_sets = [1, 2, 3, 4, 5, 6, 7]\n",
    "file_template = \"filtered_w5_hg_new_dia_set{}.nc\"\n",
    "\n",
    "# === Variable Conversion Mapping (name, units, scale factor) ===\n",
    "variables = {\n",
    "    \"diameter_graupel\": {\"label\": \"Graupel\", \"unit\": \"mm\", \"scale\": 1e3},\n",
    "    \"diameter_hail\": {\"label\": \"Hail\", \"unit\": \"mm\", \"scale\": 1e3},\n",
    "}\n",
    "\n",
    "# === Store results grouped by variable\n",
    "stats_by_var = {var: {} for var in variables}\n",
    "\n",
    "# === Loop over datasets\n",
    "for i in selected_sets:\n",
    "    file_path = os.path.join(input_dir, file_template.format(i))\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    ds = xr.open_dataset(file_path)\n",
    "\n",
    "    for varname, props in variables.items():\n",
    "        if varname not in ds:\n",
    "            print(f\"Variable {varname} not found in set {i}\")\n",
    "            continue\n",
    "\n",
    "        data = ds[varname] * props[\"scale\"]\n",
    "        vals = data.values.flatten()\n",
    "        vals = vals[~np.isnan(vals)]\n",
    "\n",
    "        # Compute statistics\n",
    "        stats = {\n",
    "            \"max\": np.nanmax(vals),\n",
    "            \"p99\": np.nanpercentile(vals, 99),\n",
    "            \"p95\": np.nanpercentile(vals, 95),\n",
    "            \"median\": np.nanmedian(vals),\n",
    "            \"mean\": np.nanmean(vals),\n",
    "           }\n",
    "        stats_by_var[varname][f\"set{i}\"] = stats\n",
    "\n",
    "    ds.close()\n",
    "\n",
    "# === Print grouped by variable\n",
    "for varname, set_stats in stats_by_var.items():\n",
    "    label = variables[varname][\"label\"]\n",
    "    unit = variables[varname][\"unit\"]\n",
    "    print(f\"\\n=== {label} Diameter Stats [{unit}] ===\")\n",
    "    print(f\"{'Dataset':<8}  {'Max':>8}  {'99th':>8}  {'95th':>8}  {'Median':>8}  {'Mean':>8}\")\n",
    "    print(\"-\" * 55)\n",
    "    for dataset, stats in set_stats.items():\n",
    "        print(f\"{dataset:<8}  {stats['max']:8.2f}  {stats['p99']:8.2f}  {stats['p95']:8.2f}  \"\n",
    "              f\"{stats['median']:8.2f}  {stats['mean']:8.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfbaf32-91d3-4b50-a7f5-4bdeda3d5bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2024b",
   "language": "python",
   "name": "npl-2024b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
